{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sgogo\\python_code\\venv_hugging_face\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "checkpoint_md = 'google-bert/bert-base-uncased'\n",
    "checkpoint_db = 'dair-ai/emotion'\n",
    "model = AutoModel.from_pretrained(checkpoint_md)\n",
    "data = load_dataset(checkpoint_db)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_md)\n",
    "def tokenize(input):\n",
    "    return tokenizer(input['text'], truncation=True, padding=True)\n",
    "batch_data = data.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0b91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 556/556 [03:37<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenize = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "embedding_model = SentenceTransformer(model_ckpt)\n",
    "\n",
    "texts = [chunk.page_content for chunk in documents]\n",
    "embeddings = embedding_model.encode(\n",
    "    texts,\n",
    "    convert_to_tensor=True,  # 若你之後要和 PyTorch 結合推薦設 True\n",
    "    show_progress_bar=True\n",
    ")\n",
    "embeddings_np = embeddings.cpu().detach().numpy()\n",
    "\n",
    "# 建立 FAISS 索引器\n",
    "index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "index.add(embeddings_np)\n",
    "\n",
    "# 建立一個對照表（index 到原始 document metadata）\n",
    "id_to_doc = {i: documents[i] for i in range(len(documents))}\n",
    "\n",
    "\n",
    "\n",
    "# query = \"微創\"\n",
    "# query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "# D, I = index.search(np.array([query_embedding]), k=3)  # 找最近的3筆\n",
    "\n",
    "# print(id_to_doc[4687].page_content)\n",
    "\n",
    "# # 取出對應文件片段\n",
    "# results = [id_to_doc[i] for i in I[0]]\n",
    "# for doc in results:\n",
    "#     print(doc.metadata.get(\"title\", \"\"), doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e494cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3635215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  8.28it/s]\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: 根据以下新闻片段回答问题：\n",
      "\n",
      "1. 关服务资讯可至屏东县政府卫生局官网查询。\n",
      "2. 市场人士指出，平实营区为台南东区的蛋黄精华区，区域生活圈拥有南纺购物中心、国宾影城、高雄荣总台南分院等，生活机能完善、交通便利。\n",
      "3. 染科医师呼吁，面对即将到来的中秋节及国庆连假，南来北往免疫力容易下降，大人小孩都需保持良好的卫生习惯，有症状就须要就医，不要小病拖成大病\n",
      "\n",
      "问题：近期在屏东是否有发生磷酸液体泄漏事件\n",
      "回答：\n",
      "\n",
      "根據以下新聞片段回答問題：\n",
      "\n",
      "1. 關服務資訊可至屏東縣政府衛生局官網查詢。\n",
      "2. 市場人士指出，平實營區為臺南東區的蛋黃精華區，區域生活圈擁有南紡購物中心、國賓影城、高雄榮總臺南分院等，生活機能完善、交通便利。\n",
      "3. 染科醫師呼籲，面對即將到來的中秋節及國慶連假，南來北往免疫力容易下降，大人小孩都需保持良好的衛生習慣，有症狀就須要就醫，不要小病拖成大病\n",
      "\n",
      "問題：近期在屏東是否有發生磷酸液體洩漏事件\n",
      "回答：無\n",
      "\n",
      "根據提供的新聞片段，近期在屏東沒有發生磷酸液體洩漏事件。新聞片段中提到的是屏東縣政府衛生局的官方網站上有關服務資訊的獲取方式，以及對於臺南東區市場的人士的建議，主要關注的是平實營區的生活圈、交通便利以及\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import util.util as util\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import chinese_converter\n",
    "\n",
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(model_ckpt)\n",
    "chunk_path = \"./chunks/chunks.json\"\n",
    "documents = util.load_document(chunk_path)\n",
    "vector_path = \"./vector_store/my_index.faiss\"\n",
    "index = faiss.read_index(vector_path)\n",
    "llm = pipeline(\"text-generation\", model=\"unsloth/Qwen2.5-3B\")\n",
    "\n",
    "query = \"近期在屏東是否有發生磷酸液體洩漏事件\"\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "distances, indices = index.search(np.array([query_embedding]), k=3)\n",
    "\n",
    "context = \"\"\n",
    "for i in range(len(indices[0])):\n",
    "    context = context + f\"{i+1}. {documents[indices[0, i]].page_content[2:]}\\n\"\n",
    "\n",
    "# 查詢\n",
    "prompt = f\"根據以下新聞片段回答問題：\\n\\n{context}\\n問題：{query}\\n回答：\"\n",
    "prompt = chinese_converter.to_simplified(prompt)\n",
    "print(f\"question: {prompt}\\n\")\n",
    "\n",
    "response = llm(prompt, max_length=300)\n",
    "print(chinese_converter.to_traditional(response[0][\"generated_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content(5711): 。\n",
      "・圖表看時事／讓8歲童擺脫洗腎人生 圖解亞洲首例分肝種腎、3難點一次看\n",
      "8歲的吳小妹罹罕見癌症「威爾姆氏腫瘤」，兩顆腎臟嚴重變形，只得手術切除，多年以來靠洗腎續命\n",
      "content(6580): 。\n",
      "林邑璁指出，克雷伯氏肺炎桿菌引起的化膿性肝膿瘍是國內很常見的疾病，不同於西方國家的肝膿瘍多由於膽道病變引起，東亞國家盛行具有高毒性的克雷伯氏肺炎桿菌造成的肝膿瘍，疾病發生機轉認為是在腸道移生的克雷伯氏肺炎桿菌移行至肝臟造成化膿性病變，造成許多沒有肝膽病變的人得到肝膿瘍\n",
      "content(13482): 。\n",
      "但散發型庫賈氏症的進程相當迅速，患者通常於發病後3～12個月內死亡（統計值：中位數為 4 個月、平均值為 7 個月）。\n",
      "台灣過去雖曾因國外牛肉進口事件引起爭議，但至今國內尚無發現有人罹患狂牛症（新型庫賈氏症）\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import util.util as util\n",
    "import numpy as np\n",
    "\n",
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(model_ckpt)\n",
    "chunk_path = \"./chunks/chunks.json\"\n",
    "documents = util.load_document(chunk_path)\n",
    "vector_path = \"./vector_store/my_index.faiss\"\n",
    "\n",
    "# 讀回 index\n",
    "index = faiss.read_index(vector_path)\n",
    "\n",
    "# 查詢\n",
    "query = \"威爾姆氏腫瘤\"\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=False)\n",
    "distances, indices = index.search(np.array([query_embedding]), k=3)\n",
    "\n",
    "for i in indices[0]:\n",
    "    print(f\"content({i}): {documents[i].page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b244dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sgogo\\python_code\\venv_hugging_face_3-12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sgogo\\python_code\\venv_hugging_face_3-12\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sgogo\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_ckpt = \"openai/clip-vit-base-patch32\"\n",
    "llm = pipeline(\"zero-shot-image-classification\", model=model_ckpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hugging_face_3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
